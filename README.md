# æ—¥æœ¬èªREADME | [English README](README_en.md)
# Nekomimi-QLoRA ğŸ¾âœ¨
ãƒã‚³è€³ãƒ¡ã‚¤ãƒ‰å£èª¿LoRA â€“ RTX 3070/4070/T4 ã§å‹•ãè»½é‡QLoRAå®Ÿè£…

![demo](screenshots/sample.png)

---

## âœ¨ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Qwen2.5-1.5B-Instruct ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã€Œå„ªã—ã„ãƒã‚³è€³ãƒ¡ã‚¤ãƒ‰å£èª¿ã€ã‚’å­¦ç¿’ã•ã›ãŸæœ€å°å®Ÿè£…ã§ã™ã€‚å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ä¾‹ç¨‹åº¦ï¼‰ã§ã‚‚ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§ã‚’ä»˜ä¸ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

---

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆneko-lora ç’°å¢ƒãƒ»mamba/micromamba æ¨å¥¨ï¼‰

1) å–å¾—
```bash
git clone https://github.com/Mainlst/nekomimi-qlora.git
cd nekomimi-qlora
```

2) ç’°å¢ƒä½œæˆï¼ˆmicromamba/mamba â†’ conda â†’ venv ã®é †ã§è‡ªå‹•ï¼‰
```bash
bash scripts/setup_env.sh
```

æ‰‹å‹•ã®ä¾‹ï¼ˆmicromambaãŒã‚ã‚‹å ´åˆï¼‰
```bash
micromamba create -n neko-lora -f environment.yml -y
micromamba run -n neko-lora python -m pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision --upgrade  # ä»»æ„
```

venv ã‚’ä½¿ã†å ´åˆï¼ˆæœ€å°ï¼‰
```bash
python -m venv .venv-neko-lora
source .venv-neko-lora/bin/activate
python -m pip install -r requirements.txt
```

---

## ğŸ§ª å­¦ç¿’ï¼ˆ8GBå®‰å…¨ãƒ©ã‚¤ãƒ³ã¨ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰

æœ€å°æ§‹æˆï¼ˆ8GBæƒ³å®šï¼‰:
```bash
# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆé‡ã„DL/å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€æˆæœç‰©ã®é››å½¢ã‚’å‡ºåŠ›ï¼‰
bash scripts/train.sh configs/maid_1p5b_stable.yaml --dry-run

# å®Ÿå­¦ç¿’
bash scripts/train.sh configs/maid_1p5b_stable.yaml
```

ãƒã‚¤ãƒ³ãƒˆ
- è¨­å®šã¯ `configs/*.yaml` ã§ç®¡ç†ï¼ˆä¾‹: `maid_1p5b_stable.yaml`/`maid_1p5b_std.yaml`/`maid_3b_edge.yaml`ï¼‰
- `train_maid.py --config <yaml>` ã§èª­ã¿è¾¼ã¿ï¼ˆseqâ†’max_lengthã€LoRA r/alpha/dropoutã€target_modules ã‚‚åæ˜ ï¼‰
- æ—¢å®šã®ã‚¢ãƒ€ãƒ—ã‚¿ä¿å­˜å…ˆ: `out/maid-qlora/adapter`
- ãƒ­ã‚°/ãƒ¡ãƒˆãƒªã‚¯ã‚¹/å›³ã¯ã€Œconfigãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã€ã«ä¿å­˜ï¼ˆä¾‹: `configs/metrics.json`, `configs/artifacts/learning_curve.png` ãªã©ï¼‰

---

## ğŸ’¬ æ¨è«–ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆ mild/sweet/ultraï¼‰

ãƒ—ãƒªã‚»ãƒƒãƒˆä»˜ãã®ç°¡æ˜“CLI:
```bash
# sweet ãƒ—ãƒªã‚»ãƒƒãƒˆã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ
bash scripts/infer.sh "æ˜æ—¥ã®æœã‚„ã‚‹ã¹ãã“ã¨ã‚’3ã¤ã ã‘æ•™ãˆã¦" sweet

# ç›´æ¥æŒ‡å®šï¼ˆä»»æ„ã§ãƒ™ãƒ¼ã‚¹/ã‚¢ãƒ€ãƒ—ã‚¿ã®åˆ‡æ›¿ã‚‚å¯èƒ½ï¼‰
micromamba run -n neko-lora python -u chat_maid.py \
  --prompt "çŸ­ã„å¿œæ´ã‚’ä¸€è¨€" --preset mild \
  --base Qwen/Qwen2.5-1.5B-Instruct \
  --adapter out/maid-qlora/adapter
```

ãƒ—ãƒªã‚»ãƒƒãƒˆå®šç¾©: `presets/infer.json`
- mild: temperature=0.6, top_p=0.9, repetition_penalty=1.05
- sweet: 0.7, 0.9, 1.05
- ultra: 0.8, 0.92, 1.1ï¼ˆæš´èµ°æ³¨æ„ï¼‰

---

## ğŸ“‚ æ§‹æˆï¼ˆä¸»è¦ï¼‰

- `configs/` â€¦ å­¦ç¿’è¨­å®šï¼ˆ8GBæœ€å°/æ¨å¥¨/3Bã‚¨ãƒƒã‚¸ï¼‰
- `presets/infer.json` â€¦ æ¨è«–ãƒ—ãƒªã‚»ãƒƒãƒˆ mild/sweet/ultra
- `scripts/` â€¦ ç’°å¢ƒæº–å‚™ãƒ»å­¦ç¿’/æ¨è«–ã®ãƒ˜ãƒ«ãƒ‘
  - `setup_env.sh` â€¦ neko-lora ç’°å¢ƒã‚’ micromamba/mamba/conda/venv ã®é †ã§æ§‹ç¯‰
  - `train.sh` / `infer.sh`
- `data/`
  - `style_maid_100.jsonl` â€¦ ã‚µãƒ³ãƒ—ãƒ«SFTãƒ‡ãƒ¼ã‚¿
  - `make_style_maid_200.py` â€¦ 100â†’200ä»¶ã¸æ‹¡å¼µï¼ˆ[STYLE=maid] å‰ç½®ã€ã‚«ãƒ†ã‚´ãƒªå‡ç­‰åŒ–ï¼‰
  - `validate.py` â€¦ JSONLæ¤œè¨¼ï¼ˆä»¶æ•°/é‡è¤‡ç‡/å¹³å‡é•·ã•ï¼‰
- `eval/prompts_100.txt` â€¦ è©•ä¾¡ç”¨å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé››å½¢ï¼‰
- `Makefile` â€¦ `make setup/train/infer/validate/data200`
- `results/metrics/` / `reports/` / `assets/screenshots/` â€¦ æˆæœç‰©ã®ç½®ãå ´
- `train_maid.py` â€¦ QLoRAå­¦ç¿’ï¼ˆ--configå¯¾å¿œã€dry-runå¯¾å¿œï¼‰
- `chat_maid.py` â€¦ LoRAæ¨è«–ï¼ˆ--preset/--prompt å¯¾å¿œï¼‰
- `examples/infer_minimal.py` â€¦ æœ€å°æ¨è«–ã‚µãƒ³ãƒ—ãƒ«

---

## å®Ÿé¨“é‹ç”¨ã‚¬ã‚¤ãƒ‰ ğŸ§ªï¼ˆç°¡æ˜“ï¼‰

æ¨å¥¨ãƒ–ãƒ©ãƒ³ãƒé‹ç”¨
- `main`ï¼ˆå®‰å®šï¼‰ / `exp/*`ï¼ˆå®Ÿé¨“ï¼‰ / `demo/*`ï¼ˆä½œå“ï¼‰

æˆæœç‰©ã®ç½®ãå ´
- `reports/`ï¼ˆè¡¨ãƒ»æ‰€æ„Ÿï¼‰
- `results/metrics/`ï¼ˆJSONãƒ­ã‚°ï¼‰
- `assets/screenshots/`ï¼ˆUIã‚„æ¯”è¼ƒã®ã‚¹ã‚¯ã‚·ãƒ§ï¼‰

è£œè¶³ï¼ˆæ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼‰
- `scripts/new_exp.sh` ã¨ `scripts/run_exp.sh` ã‚‚ä½µç”¨å¯èƒ½ã§ã™ï¼ˆexperiments/é…ä¸‹ã«é››å½¢ç”Ÿæˆï¼‰ã€‚

### Windowsï¼ˆPowerShellï¼‰

```powershell
./scripts/run_exp.ps1 -Config "experiments/2025-08-30-lora-qlora/config.yaml"
```

### é–‹ç™ºã®è¶³å ´ï¼ˆä»»æ„ï¼‰

- ãƒ—ãƒªã‚³ãƒŸãƒƒãƒˆ
  - è¨­å®š: `.pre-commit-config.yaml`
  - æœ‰åŠ¹åŒ–:
    ```bash
    pip install pre-commit
    pre-commit install
    ```
- æœ€å°CIï¼ˆGitHub Actionsï¼‰
  - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: `.github/workflows/ci.yml`
  - ç›®çš„: ä¾å­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¹ã‚¿ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯ã®ã‚¹ãƒ¢ãƒ¼ã‚¯

### é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ¨å¥¨ï¼‰

- ãƒ–ãƒ©ãƒ³ãƒ: `main`ï¼ˆå®‰å®šï¼‰, `exp/<æ—¥ä»˜>-<çŸ­å>`, `demo/<åå‰>`, `feat/<ç›®çš„>`, `fix/<å†…å®¹>`
- ã‚³ãƒŸãƒƒãƒˆä¾‹: `exp: run qlora on 3e-4 with cosine schedule`
- ç¯€ç›®ã¯ã‚¿ã‚°/Releaseã€`CHANGELOG.md`æ›´æ–°

---

## ğŸ”® å¿œç”¨ã‚¢ã‚¤ãƒ‡ã‚¢

* ä»–ã®ã‚­ãƒ£ãƒ©å£èª¿ LoRAï¼ˆåŸ·äº‹ã€é–¢è¥¿å¼ã€è‹±èªç‰ˆï¼‰
* ChatBot ã‚„ Discord Bot ã¸ã®çµ„ã¿è¾¼ã¿
* NPC å¯¾è©±ã‚„ã‚²ãƒ¼ãƒ  AI ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚º

---

## ğŸ“œ License

MIT License

---

## ğŸ“– Citation

```bibtex
@software{maid_qlora,
	author = {Your Name},
	title = {Maid-QLoRA: ãƒã‚³è€³ãƒ¡ã‚¤ãƒ‰å£èª¿LoRA},
	year = {2025},
	url = {https://github.com/yourname/nekomimi-qlora},
}
```
